# 在其他应用中调用本项目模型的快速集成指南

本指南面向“让 AI/开发者快速在任意应用中复用本项目的模型配置”。
提供两种方式：
- 方式 A（推荐）：直接复用本项目的运行器函数 `chat_once()`，最省事。
- 方式 B（通用）：复制一段最小依赖的调用函数到你的应用中（只依赖 `requests`）。

目录/文件：
- 模型目录：`docs/data/template/models/`
- 模型索引：`docs/data/template/models/index.json`
- 运行器：`backend/openai_compat_runner.py`（提供 `chat_once()`）
- 说明文档：本目录 `openai_compat_runner_说明.md`

## 0. 准备
- Python ≥ 3.10
- 安装依赖（如你的应用环境没有 `requests`）：
```powershell
pip install requests
```
- 设置对应模型需要的 API Key（以 PowerShell 为例）：
```powershell
# Qwen/DashScope
$env:QWEN_API_KEY = "sk-..."

# Moonshot
$env:MOONSHOT_API_KEY = "sk-..."
```
- 可选：临时上调统一超时（秒），无需修改 JSON：
```powershell
$env:OPENAI_TIMEOUT = "60"
```
超时语义与优先级详见：本目录 `openai_compat_runner_说明.md`

## 1. 方式 A：复用本项目的函数（最省事）
在你的 Python 应用中直接导入并调用：
```python
from pathlib import Path
from backend.openai_compat_runner import chat_once

# 指向任意一个模型 JSON（示例：deepseek-v3）
model_json = str(Path(r"d:/AI-Projects/Autogen_CLI_Factory/refactoring/docs/data/template/models/qwen_deepseek_v3.json"))

resp = chat_once(model_json, "用中文简要自我介绍")
if resp.get("ok"):
    print("== model text ==\n", resp.get("text"))
else:
    print("== error ==\n", resp)
```
说明：
- `chat_once(model_file, user_text)` 会读取 JSON，自动从 `config.api_key_env` 获取密钥，访问 `base_url/chat/completions` 并返回结构化结果。
- 结果包含 `ok/status_code/text/data/duration_ms` 等字段。

## 2. 方式 B：复制最小调用函数（仅依赖 requests）
如果不方便引入本项目代码，可将以下函数复制进你的应用（保持 OpenAI 兼容调用）：
```python
import os, json, requests

def call_openai_compatible(model_json_path: str, user_text: str) -> dict:
    cfg = json.loads(open(model_json_path, "r", encoding="utf-8").read())
    config = cfg.get("config", {})
    model = config.get("model") or config.get("deployment")
    base_url = (config.get("base_url") or config.get("endpoint") or "").rstrip("/")
    if not model or not base_url:
        raise ValueError("model/base_url is required in model json")
    api_key_env = config.get("api_key_env")
    api_key = os.getenv(api_key_env or "")
    if not api_key:
        raise RuntimeError(f"Environment variable {api_key_env} not set")

    params = config.get("parameters") or {}
    timeout = params.get("timeout") or 120
    # 环境变量覆盖（最高优先）
    for env_name in ("OPENAI_TIMEOUT", "OPENAI_COMPAT_TIMEOUT"):
        v = os.getenv(env_name)
        if v:
            try:
                tv = float(v)
                if tv > 0:
                    timeout = tv
                    break
            except Exception:
                pass

    url = f"{base_url}/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": cfg.get("system_message") or "You are a helpful assistant."},
            {"role": "user", "content": user_text},
        ],
    }
    for k in ("temperature", "max_tokens", "top_p", "presence_penalty", "frequency_penalty"):
        if k in params and params[k] is not None:
            payload[k] = params[k]

    r = requests.post(url, headers=headers, json=payload, timeout=timeout)
    out = {"status_code": r.status_code, "ok": r.ok}
    try:
        data = r.json()
        out["data"] = data
        if isinstance(data, dict):
            ch = (data.get("choices") or [])
            if ch and isinstance(ch, list):
                out["text"] = (ch[0].get("message") or {}).get("content")
    except Exception:
        out["text"] = r.text
    return out
```
使用示例：
```python
resp = call_openai_compatible(
    r"d:/AI-Projects/Autogen_CLI_Factory/refactoring/docs/data/template/models/moonshot_kimi_k2.json",
    "给我5条高效工作的小建议"
)
print(resp.get("text"))
```

## 3. Node.js/TypeScript（可选）
如需在前端/Node应用中直接走 OpenAI 兼容协议（无需后端转发）：
```ts
import fetch from 'node-fetch';
import fs from 'fs';

async function callWithJson(modelJsonPath: string, userText: string) {
  const cfg = JSON.parse(fs.readFileSync(modelJsonPath, 'utf-8'));
  const baseUrl = (cfg.config.base_url || cfg.config.endpoint).replace(/\/$/, '');
  const model = cfg.config.model || cfg.config.deployment;
  const apiKeyEnv = cfg.config.api_key_env;
  const apiKey = process.env[apiKeyEnv];
  if (!apiKey) throw new Error(`Env ${apiKeyEnv} not set`);

  const body: any = {
    model,
    messages: [
      { role: 'system', content: cfg.system_message || 'You are a helpful assistant.' },
      { role: 'user', content: userText },
    ],
  };
  const p = cfg.config.parameters || {};
  for (const k of ['temperature','max_tokens','top_p','presence_penalty','frequency_penalty']){
    if (p[k] !== undefined && p[k] !== null) body[k] = p[k];
  }

  const timeout = Number(process.env.OPENAI_TIMEOUT || p.timeout || 120);
  const ctrl = new AbortController();
  const timer = setTimeout(() => ctrl.abort(), timeout * 1000);
  try {
    const resp = await fetch(`${baseUrl}/chat/completions`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
      body: JSON.stringify(body),
      signal: ctrl.signal,
    });
    const data = await resp.json().catch(async () => ({ text: await resp.text() }));
    return { ok: resp.ok, status: resp.status, data, text: data?.choices?.[0]?.message?.content };
  } finally {
    clearTimeout(timer);
  }
}
```

## 4. cURL（调试）
```powershell
$MODEL = "deepseek-v3"
$BASE  = "https://dashscope.aliyuncs.com/compatible-mode/v1"
$KEY   = $env:QWEN_API_KEY

curl "$BASE/chat/completions" `
  -H "Content-Type: application/json" `
  -H "Authorization: Bearer $KEY" `
  -d (@{ model=$MODEL; messages=@(@{role="user"; content="你是谁"}) } | ConvertTo-Json)
```

## 5. 选择模型文件
在目录 `docs/data/template/models/` 中可直接选择下列任意 JSON：
- `qwen_deepseek_r1.json`
- `qwen_deepseek_v3.json`
- `qwen_turbo_latest.json`
- `qwen_vl_plus_latest.json`
- `qwen2_5_vl_72b_instruct.json`
- `moonshot_kimi_k2.json`

也可用索引 `docs/data/template/models/index.json` 进行遍历或 UI 选择。

## 6. 常见问题
- 未设置 API Key：确保模型 JSON 的 `config.api_key_env` 对应的环境变量存在，值为 ASCII 字符串（避免中文/占位符）。
- 超时：默认 30s（存于部分模型 `parameters.timeout`），可改当前模型 JSON，或用 `OPENAI_TIMEOUT` 临时覆盖。
- 乱码/编码：见本目录 `openai_compat_runner_说明.md` 与运行器增强的诊断字段（`content_type/encoding/apparent_encoding/body_preview`）。

## 7. 与 Autogen 0.6.2 的契合
- 模型参数完全以静态 JSON 配置驱动（三库统一 `db` 字段），符合“以数据为核心、前端优先适配”的原则。
- 在你的应用内只需选择一个模型 JSON 并按上述方式调用，即可获得稳定的 OpenAI 兼容能力，无需强依赖后端。
